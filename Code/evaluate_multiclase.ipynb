{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegir que experimento evaluar\n",
    "NUM_CLASSES = 7 \n",
    "directorio_experimento = f'./{NUM_CLASSES}_class'\n",
    "\n",
    "os.chdir(directorio_experimento)\n",
    "reporte_folder = f'reporte_{NUM_CLASSES}_class'\n",
    "if not os.path.exists(reporte_folder):\n",
    "    os.mkdir(reporte_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos = pd.read_csv('/database/bd_aumentada/database_augment.csv')\n",
    "df_rendimiento = pd.read_csv('rendimiento_experimento.csv')\n",
    "# cambiar para el numero de clases\n",
    "# class_list = datos[f'Class_cat_{NUM_CLASSES}'].unique().tolist()\n",
    "print('El rendimiento del experimento fue: ')\n",
    "display(df_rendimiento)\n",
    "desc = df_rendimiento[['acc', 'loss']].describe()\n",
    "desc.to_csv('describe_experimento.csv')\n",
    "display(desc)\n",
    "print(f'La precision total fue de: {df_rendimiento.acc.mean()} (+/- {df_rendimiento.acc.std()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos el mejor elemento\n",
    "best_index = df_rendimiento.acc.idxmax()\n",
    "best_folder = f'fold_{best_index}'\n",
    "print(f'El mejor rendimiento fue encontrado en el: {best_folder}')\n",
    "\n",
    "rendimiento_fold = df_rendimiento.acc.max()\n",
    "print(rendimiento_fold)\n",
    "df_log = pd.read_csv(os.path.join(best_folder, 'log.csv'))\n",
    "display(df_log)\n",
    "acc = df_log.accuracy.values\n",
    "val_accuracy = df_log.val_accuracy.values\n",
    "\n",
    "loss = df_log.loss.values\n",
    "val_loss = df_log.val_loss.values\n",
    "ep = range(len(acc))\n",
    "mejor = df_log.val_accuracy.idxmax()\n",
    "display(df_log.iloc[mejor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mejor > rendimiento_fold:\n",
    "    model_file = 'model.best.h5'\n",
    "else:\n",
    "    model_file = 'model.h5'\n",
    "    \n",
    "BATCH_SIZE = 256\n",
    "WIDTH = 256 # 256\n",
    "HEIGHT = 256 # 256\n",
    "SEED = 111091\n",
    "    \n",
    "model = tf.keras.models.load_model(f'./{best_folder}/{model_file}')\n",
    "\n",
    "# model = tf.saved_model.load(os.path.join(best_folder, 'vgg19_multiclass'))\n",
    "datos_val = pd.read_csv(os.path.join(best_folder, 'datos_val.csv'))\n",
    "    \n",
    "test_datagen =tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(datos_val, \n",
    "                                      None, \n",
    "                                      x_col='file', \n",
    "                                      target_size=(WIDTH, HEIGHT),\n",
    "                                      y_col=f'Class_cat_{NUM_CLASSES}', \n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      seed=SEED,\n",
    "                                      has_ext=True,\n",
    "                                      class_mode='categorical', \n",
    "                                      shuffle=False)\n",
    "class_list = list(test_generator.class_indices.keys())\n",
    "print('Validando')\n",
    "Y_pred = model.predict(test_generator, verbose=1, steps=math.ceil(test_generator.samples/test_generator.batch_size), workers=16)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "validacion = dict(file=test_generator.filepaths, \n",
    "                  y=test_generator.classes, \n",
    "                  y_pred=y_pred, \n",
    "                  y_raw=np.round(Y_pred, 4).tolist())\n",
    "\n",
    "df_val = pd.DataFrame(validacion)\n",
    "df_val[f'Class_cat_{NUM_CLASSES}'] = df_val['y']\n",
    "df_val[f'Class_cat_{NUM_CLASSES}_pred'] = df_val['y_pred']\n",
    "class_dict = dict((v,k) for k,v in test_generator.class_indices.items())\n",
    "df_val = df_val.replace({f\"Class_cat_{NUM_CLASSES}\": class_dict, f\"Class_cat_{NUM_CLASSES}_pred\": class_dict})\n",
    "df_val.to_csv(os.path.join(reporte_folder, 'validacion.csv'))\n",
    "df_val['correcto'] = np.where(df_val['y']==df_val['y_pred'],True, False)\n",
    "incorrectos = df_val[df_val['correcto']==False]\n",
    "incorrectos = pd.merge(incorrectos,datos_val, on='file', how='inner')\n",
    "incorrectos.to_csv(os.path.join(reporte_folder,'incorrectos.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision normal\n",
    "utils.grafica_metricas(ep, acc, val_accuracy, etiqueta='Exactitud', \n",
    "                 titulo=f'Exactitud en entrenamiento y validación para {NUM_CLASSES} clases',\n",
    "                 archivo=f'{reporte_folder}/acc',\n",
    "                 suavizado=False)\n",
    "\n",
    "# precision suave\n",
    "utils.grafica_metricas(ep, acc, val_accuracy, etiqueta='Exactitud', \n",
    "                 titulo=f'Exactitud en entrenamiento y validación para {NUM_CLASSES} clases (suavizado exponencial: 0.8)',\n",
    "                 archivo=f'{reporte_folder}/acc_smooth',\n",
    "                 suavizado=True)\n",
    "\n",
    "# perdida normal\n",
    "utils.grafica_metricas(ep, loss, val_loss, etiqueta='Pérdida', \n",
    "                 titulo=f'Pérdida en entrenamiento y validación para {NUM_CLASSES} clases',\n",
    "                 archivo=f'{reporte_folder}/loss',\n",
    "                 suavizado=False)\n",
    "# perdida suave\n",
    "utils.grafica_metricas(ep, loss, val_loss, etiqueta='Pérdida', \n",
    "                 titulo=f'Pérdida en entrenamiento y validación para {NUM_CLASSES} clases (suavizado exponencial: 0.8)',\n",
    "                 archivo=f'{reporte_folder}/loss_smooth',\n",
    "                 suavizado=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variabilidad exactitud\n",
    "utils.variabilidad_metricas(df_log[['accuracy', 'val_accuracy']], 'Exactitud', \n",
    "                      f'Variabilidad entre ambas exactitudes para {NUM_CLASSES} clases',\n",
    "                      f'{reporte_folder}/variabilidad_acc', fontsize=10)\n",
    "# variabilidad perdida\n",
    "utils.variabilidad_metricas(df_log[['loss', 'val_loss']], 'Pérdida', \n",
    "                      f'Variabilidad entre ambas pérdidas para {NUM_CLASSES} clases',\n",
    "                      f'{reporte_folder}/variabilidad_loss', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.boxplot_metricas(df_log[['loss', 'val_loss']], \n",
    "                 f'Gráfico de caja para la pérdida en entrenamiento y en validación para {NUM_CLASSES} clases', 'tab20c',\n",
    "                 f'{reporte_folder}/box_loss')\n",
    "\n",
    "utils.boxplot_metricas(df_log[['accuracy', 'val_accuracy']], \n",
    "                 f'Gráfico de caja para las métricas en entrenamiento y en validación para {NUM_CLASSES} clases', 'tab20b',\n",
    "                 f'{reporte_folder}/box_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = utils.evaluar_clasificacion(df_val, NUM_CLASSES, f'reporte_{NUM_CLASSES}_class/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_confusion_matrix(cm, f'{reporte_folder}/matriz',\n",
    "                      title=f'Matriz de confusion para {NUM_CLASSES} clases', \n",
    "                      normalize=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_confusion_matrix(cm, archivo=f'{reporte_folder}/matriz',\n",
    "                      title=f'Matriz de confusion para {NUM_CLASSES} clases', \n",
    "                      normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.mostrar_reporte(f'{reporte_folder}/reporte_clasificacion.csv')\n",
    "utils.mostrar_reporte(f'{reporte_folder}/reporte_metricas_malas.csv')\n",
    "utils.mostrar_reporte(f'{reporte_folder}/reporte_metricas_diagnostico.csv')\n",
    "utils.mostrar_reporte(f'{reporte_folder}/reporte_metricas_clasificacion.csv')\n",
    "utils.mostrar_reporte(f'{reporte_folder}/reporte_cero.csv')\n",
    "utils.mostrar_reporte(f'{reporte_folder}/reporte_uno.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(filename=f'{reporte_folder}/reporte_html.html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.grafica_reporte_uno(NUM_CLASSES, archivo=f'{reporte_folder}/reporte_uno')\n",
    "utils.grafica_reporte_cero(NUM_CLASSES, archivo=f'{reporte_folder}/reporte_cero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_CLASSES == 2:\n",
    "    utils.grafica_roc(df_val, NUM_CLASSES, archivo=f'{reporte_folder}/roc')\n",
    "else:\n",
    "    utils.roc_multiclass(NUM_CLASSES, df_val['y'].values, df_val['y_pred'].values, class_list, archivo=f'{reporte_folder}/roc_multiclase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrectos = pd.read_csv(os.path.join(reporte_folder, 'incorrectos.csv'))\n",
    "# incorrectos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectos = incorrectos.rename(columns={\"Class_cat_7_x\": 'Class_cat_7'})\n",
    "conteo_incorrectos = incorrectos.groupby(['Class_cat_7']).agg(['count'])\n",
    "display(conteo_incorrectos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "muestras = []\n",
    "for ele in list(conteo_incorrectos.index):\n",
    "    m = incorrectos[incorrectos['Class_cat_7'] == ele].sample(n=1)\n",
    "    muestras.append(m)\n",
    "df_muestras = pd.concat(muestras)\n",
    "df_muestras.to_csv(os.path.join(reporte_folder, 'muestreo_incorrectos.csv'))\n",
    "display(df_muestras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.imagen_muestras_erroneas(df_muestras, NUM_CLASSES, folder= f'{reporte_folder}/muestras_erroneas', font=f'../fonts/computer-modern/cmunssdc.ttf', size=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}