{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from math import ceil\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import display\n",
    "from pytictoc import TicToc\n",
    "from utils import PlotLosses, grafica_kfold\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "ruta = os.path.abspath(r'./')\n",
    "directorio_experimento = os.path.join(ruta, f'{NUM_CLASSES}_class')\n",
    "if not os.path.exists(directorio_experimento):\n",
    "    os.mkdir(directorio_experimento)\n",
    "os.chdir(directorio_experimento)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dropout, fc_layers, num_classes, opt, metrics=['accuracy']):\n",
    "\n",
    "    base_model = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, input_shape=(HEIGHT, WIDTH, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x =  tf.keras.layers.Flatten()(x)\n",
    "    for fc, drop in zip(fc_layers, dropout):\n",
    "        x =  tf.keras.layers.Dense(fc, activation='relu')(x)\n",
    "        x =  tf.keras.layers.Dropout(drop)(x)\n",
    "\n",
    "    predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    finetune_model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    finetune_model.compile(opt, loss='categorical_crossentropy', metrics=metrics)\n",
    "\n",
    "    return finetune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "WIDTH = 256 # 256\n",
    "HEIGHT = 256 # 256\n",
    "FC_LAYERS = [1024 * 1, 1024  * 1]  # 1024\n",
    "LR = 1e-5\n",
    "OPT = tf.keras.optimizers.Adam(lr=LR)\n",
    "SEED = 111091\n",
    "np.random.seed(SEED)\n",
    "EPOCHS = 30 # 60\n",
    "# mostrar experimento quitando y poniendo droputs\n",
    "# con dos capas de droput el modelo infra ajusta\n",
    "# dropout esta bien\n",
    "DROPOUT = [0.5, 0.5]\n",
    "EVALUACIONES = []\n",
    "KFOLD_SPLITS = 10\n",
    "avg_acc = []\n",
    "avg_loss = []\n",
    "\n",
    "datos = pd.read_csv(f'{ruta}\\\\database\\\\bd_aumentada\\\\database_augment.csv')\n",
    "\n",
    "datos_random = datos.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "HYP = dict(batch_size=BATCH_SIZE, \n",
    "           width=WIDTH, \n",
    "           height=HEIGHT, \n",
    "           learning_rate=LR, \n",
    "           optimizer=str(OPT), \n",
    "           seed=SEED, \n",
    "           epochs=EPOCHS, \n",
    "           dropout=str(DROPOUT), \n",
    "           kfold_splits=KFOLD_SPLITS, \n",
    "           fc_layers=str(FC_LAYERS),\n",
    "           num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "HYP = {'Valor': [BATCH_SIZE, \n",
    "                 WIDTH, \n",
    "                 HEIGHT, \n",
    "                 LR, \n",
    "                 OPT, \n",
    "                 SEED, \n",
    "                 EPOCHS, \n",
    "                 DROPOUT, \n",
    "                 KFOLD_SPLITS, \n",
    "                 FC_LAYERS, \n",
    "                 NUM_CLASSES]}\n",
    "df_hyp = pd.DataFrame(HYP, \n",
    "                      index=['BATCH_SIZE', \n",
    "                             'WIDTH', \n",
    "                             'HEIGHT', \n",
    "                             'LR', \n",
    "                             'OPT', \n",
    "                             'SEED', \n",
    "                             'EPOCHS', \n",
    "                             'DROPOUT', \n",
    "                             'KFOLD_SPLITS', \n",
    "                             'FC_LAYERS', \n",
    "                             'NUM_CLASSES']\n",
    "                     )\n",
    "display(df_hyp)\n",
    "df_hyp.to_csv('hiperparametros.csv')\n",
    "\n",
    "kf = KFold(n_splits=KFOLD_SPLITS, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TicToc()\n",
    "inicio = t.tic()\n",
    "for i, (train_indices, val_indices) in enumerate(kf.split(datos_random)):\n",
    "\n",
    "    fold_dir = f'fold_{i}'\n",
    "    print(f'Iniciando Fold: {i}')\n",
    "    if not os.path.exists(fold_dir):\n",
    "        os.mkdir(fold_dir)\n",
    "    print(f'Datos de entrenamiento: {len(train_indices)}')\n",
    "    print(f'Datos de validacion: {len(val_indices)}')\n",
    "    print('Dividiendo datos')\n",
    "    train = datos.iloc[train_indices]\n",
    "    val = datos.iloc[val_indices]\n",
    "    train.to_csv(os.path.join(fold_dir, \"datos_train.csv\"))\n",
    "    val.to_csv(os.path.join(fold_dir, \"datos_val.csv\")) \n",
    "\n",
    "    print('Construyendo modelo')\n",
    "    metrics = ['accuracy']\n",
    "    model = build_model(DROPOUT, FC_LAYERS, num_classes=NUM_CLASSES, opt=OPT, metrics=metrics)\n",
    "\n",
    "    print('Creando generadores')\n",
    "\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        # rotation_range=25,\n",
    "        fill_mode='constant'\n",
    "        \n",
    "    )\n",
    "    \n",
    "    test_datagen =tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.vgg19.preprocess_input,\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "                                          train,\n",
    "                                          None,\n",
    "                                          x_col='file',\n",
    "                                          target_size=(WIDTH, HEIGHT),\n",
    "                                          y_col=f'Class_cat_{NUM_CLASSES}', \n",
    "                                          batch_size=BATCH_SIZE, \n",
    "                                          seed=SEED,\n",
    "                                          has_ext=True,class_mode='categorical')\n",
    "\n",
    "    \n",
    "    test_generator = test_datagen.flow_from_dataframe(val, \n",
    "                                          None, \n",
    "                                          x_col='file', \n",
    "                                          target_size=(WIDTH, HEIGHT),\n",
    "                                          y_col=f'Class_cat_{NUM_CLASSES}', \n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          seed=SEED,\n",
    "                                          has_ext=True,\n",
    "                                          class_mode='categorical', \n",
    "                                          shuffle=True)\n",
    "    class_list = list(test_generator.class_indices.keys())\n",
    "    \n",
    "    with open('summary.txt', 'w') as f:\n",
    "        with redirect_stdout(f):\n",
    "            model.summary()\n",
    "            \n",
    "    tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    "    )\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f\"{fold_dir}/model.best.h5\", \n",
    "                                                 monitor=\"val_accuracy\", \n",
    "                                                 verbose=1, \n",
    "                                                 mode='max', \n",
    "                                                 save_best_only=True)\n",
    "    \n",
    "    plot_losses = PlotLosses(figsize=(10,6))\n",
    "    callbacks_list = [\n",
    "                      plot_losses, \n",
    "                      checkpoint, \n",
    "                      # tf.keras.callbacks.TensorBoard(log_dir=os.path.join(fold_dir, 'log/'), histogram_freq=1), \n",
    "                      tf.keras.callbacks.CSVLogger(os.path.join(fold_dir, 'log.csv'))\n",
    "    ]\n",
    "    print('Iniciando entrenamiento')\n",
    "    history = model.fit(train_generator, \n",
    "                        epochs=EPOCHS, \n",
    "                        workers=16, \n",
    "                        shuffle=True, \n",
    "                        callbacks=callbacks_list, \n",
    "                        verbose=1, \n",
    "                        steps_per_epoch=ceil(len(train_indices) / BATCH_SIZE),\n",
    "                        validation_data=test_generator, \n",
    "                        validation_steps=ceil(len(val_indices) / BATCH_SIZE)\n",
    "                                 )\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    avg_loss.append(val_loss[-1])\n",
    "    avg_acc.append(val_accuracy[-1]*100)\n",
    "    \n",
    "    print('Salvando modelo')       \n",
    "    tf.saved_model.save(model, os.path.join(fold_dir, \"vgg19_multiclass\"))                                                             \n",
    "    model.save(os.path.join(fold_dir, 'model.h5')) \n",
    "\n",
    "print(f'Resultados de la validación cruzada (K = {KFOLD_SPLITS})')\n",
    "print(f'Pérdida {np.mean(avg_loss)} (+/- {np.std(avg_loss)}%)')\n",
    "print(f'Precisión {np.mean(avg_acc)}% (+/- {np.std(avg_acc)}%)')\n",
    "\n",
    "final_segundos = t.tocvalue()\n",
    "final_minutos = final_segundos/60\n",
    "final_horas = final_minutos/60\n",
    "\n",
    "print('Tiempo transcurrido')\n",
    "print(f'Segundos: {float(final_segundos)} sec')\n",
    "print(f'Minutos: {float(final_minutos)} min')\n",
    "print(f'Horas: {float(final_horas)} horas')\n",
    "\n",
    "tiempos = {'tiempo_transcurrido': [final_segundos, final_minutos, final_horas]}\n",
    "tiempo_df = pd.DataFrame(tiempos, index=['segundos', 'minutos', 'horas'])\n",
    "tiempo_df.to_csv('tiempo_experimento.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendimiento = dict(acc=avg_acc, loss=avg_loss)\n",
    "df_rendimiento = pd.DataFrame(rendimiento, index=list(range(0,KFOLD_SPLITS)))\n",
    "df_rendimiento.index.name = 'fold'\n",
    "display(df_rendimiento)\n",
    "display(df_rendimiento.describe())\n",
    "df_rendimiento.to_csv('rendimiento_experimento.csv')\n",
    "datos_kfold = datos.sort_values(by=[f'Class_num_{NUM_CLASSES}'])\n",
    "grafica_kfold(kf, datos_kfold['file'], \n",
    "              datos_kfold[f'Class_num_{NUM_CLASSES}'], \n",
    "              n_splits=KFOLD_SPLITS, \n",
    "              num_classes=NUM_CLASSES, \n",
    "              nom_archivo=f'kfold_{KFOLD_SPLITS }_{NUM_CLASSES}', \n",
    "              lw=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}